# MRIå¯¹æ¯”åº¦è¿ç§»ä¸­çš„å™ªéŸ³é—®é¢˜åˆ†æä¸è§£å†³æ–¹æ¡ˆ

## ç›®å½•
1. [é—®é¢˜åˆ†æ](#é—®é¢˜åˆ†æ)
2. [Nilaè®ºæ–‡æ ¸å¿ƒæ€æƒ³](#nilaè®ºæ–‡æ ¸å¿ƒæ€æƒ³)
3. [å½“å‰UNSBæ–¹æ³•çš„å±€é™æ€§](#å½“å‰unsbæ–¹æ³•çš„å±€é™æ€§)
4. [è§£å†³æ–¹æ¡ˆè®¨è®º](#è§£å†³æ–¹æ¡ˆè®¨è®º)
5. [æ¨èå®æ–½è·¯å¾„](#æ¨èå®æ–½è·¯å¾„)

---

## é—®é¢˜åˆ†æ

### ä½ çš„é—®é¢˜æè¿°
- **è¾“å…¥æ•°æ®**: PDå’ŒPDFséƒ½å«æœ‰å™ªéŸ³
- **ç°è±¡**: è¿ç§»ç»“æœä¸Šæœ‰ç€å’Œæ•°æ®åŒä¸€æ°´å¹³çš„å™ªéŸ³
- **æ ¹æœ¬åŸå› **: æ¨¡å‹å­¦ä¹ äº†å™ªéŸ³æ¨¡å¼ï¼Œè€Œä¸æ˜¯çº¯å‡€çš„å¯¹æ¯”åº¦è¿ç§»æ˜ å°„

### å™ªéŸ³çš„æ¥æº
MRIæ•°æ®ä¸­çš„å™ªéŸ³ä¸»è¦æ¥è‡ª:
1. **çƒ­å™ªéŸ³ (Thermal Noise)**: çº¿åœˆæ¥æ”¶è¿‡ç¨‹ä¸­çš„å›ºæœ‰å™ªéŸ³
2. **é‡‡é›†å™ªéŸ³**: å¿«é€Ÿæˆåƒã€ä½åœºå¼ºã€é«˜åŠ é€Ÿå› å­å¯¼è‡´SNRé™ä½
3. **é‡å»ºå™ªéŸ³**: kç©ºé—´æ¬ é‡‡æ ·é‡å»ºå¼•å…¥çš„ä¼ªå½±

åœ¨ä½ çš„PD/PDFsæ•°æ®ä¸­ï¼Œè¿™äº›å™ªéŸ³ä¼š:
- å¹²æ‰°æ¨¡å‹å¯¹çœŸå®è§£å‰–ç»“æ„çš„å­¦ä¹ 
- è¢«å½“ä½œ"ç‰¹å¾"ä¼ é€’åˆ°ç›®æ ‡åŸŸ
- é™ä½è¿ç§»è´¨é‡å’Œä¸´åºŠå¯ç”¨æ€§

---

## Nilaè®ºæ–‡æ ¸å¿ƒæ€æƒ³

### é—®é¢˜å®šä¹‰
Nilaè§£å†³çš„æ˜¯**å¸¦å™ªéŸ³æµ‹é‡çš„MRIé‡å»ºé—®é¢˜**:
```
è§‚æµ‹: y = Ax + Î·,  Î· ~ N(0, Ïƒ_yÂ²I)
ç›®æ ‡: ä»æ¬ é‡‡æ ·kç©ºé—´yæ¢å¤å…¨é‡‡æ ·å›¾åƒx
```

å…¶ä¸­:
- `A`: æ¬ é‡‡æ ·ç®—å­ (é‡‡æ ·mask + FFT)
- `Ïƒ_y`: æµ‹é‡å™ªéŸ³æ°´å¹³
- `Î·`: kç©ºé—´ä¸­çš„å¤é«˜æ–¯å™ªéŸ³

### æ ¸å¿ƒåˆ›æ–°: NoIse Level Adaptive Data Consistency (Nila-DC)

**é—®é¢˜è¯†åˆ«**:
æ ‡å‡†diffusioné‡å»ºåœ¨reverseè¿‡ç¨‹ä¸­ï¼Œéšç€äººå·¥å™ªéŸ³Ïƒ_té€’å‡:
```
æ—©æœŸæ­¥éª¤(å¤§t): Ïƒ_t >> Ïƒ_y  â†’ äººå·¥å™ªéŸ³å ä¸»å¯¼
æ™šæœŸæ­¥éª¤(å°t): Ïƒ_t << Ïƒ_y  â†’ æµ‹é‡å™ªéŸ³å ä¸»å¯¼ âš ï¸
```

åœ¨æ™šæœŸæ­¥éª¤ï¼Œå¦‚æœä»ä½¿ç”¨å…¨å¼ºåº¦æ•°æ®ä¸€è‡´æ€§ï¼Œä¼š**æ”¾å¤§æµ‹é‡å™ªéŸ³**ï¼

**è§£å†³æ–¹æ¡ˆ**: è‡ªé€‚åº”æ•°æ®ä¸€è‡´æ€§å¼ºåº¦
```python
# è®¡ç®—å™ªéŸ³æ¯”ç‡
ratio = (sigma_t / sqrt(alpha_t)) / sigma_y

# è‡ªé€‚åº”è°ƒæ•´DCå¼ºåº¦
if ratio < 1.0:  # å½“diffusionå™ªéŸ³ < æµ‹é‡å™ªéŸ³
    lambda_t = linear_decay(t)  # çº¿æ€§è¡°å‡åˆ°0
else:
    lambda_t = 1.0  # å…¨å¼ºåº¦DC

# åº”ç”¨è‡ªé€‚åº”DC
x_t = x_t - lambda_t * gradient_DC * step_size
```

**æ•ˆæœ**:
- æ—©æœŸ: å……åˆ†åˆ©ç”¨æ•°æ®ä¸€è‡´æ€§å¼•å¯¼ç”Ÿæˆ
- æ™šæœŸ: å‡å°‘DCå¼ºåº¦ï¼Œé¿å…å™ªéŸ³æ”¾å¤§
- æ€§èƒ½: åœ¨Ïƒ_y=0.1æ—¶ï¼ŒPSNRæå‡ ~5-6 dB

### æ•°å­¦æ¡†æ¶

**åéªŒé‡‡æ ·**:
```
p(x|y) âˆ p(y|x) Â· p(x)
       = N(y; Ax, Ïƒ_yÂ²) Â· p_diffusion(x)
```

**å…³é”®æ´å¯Ÿ**: ä¼¼ç„¶é¡¹çš„æƒé‡åº”è¯¥ä¸å™ªéŸ³æ°´å¹³ç›¸å…³:
```
âˆ‡log p(y|x) = -A^H(Ax - y) / Ïƒ_yÂ²
```

å½“Ïƒ_yå¢å¤§æ—¶ï¼Œæ¢¯åº¦æƒé‡è‡ªç„¶å‡å° â†’ åº”è¯¥å‡å°‘DCå¼ºåº¦

---

## å½“å‰UNSBæ–¹æ³•çš„å±€é™æ€§

### UNSBæ¶æ„å›é¡¾ (sb_model.py)

ä½ çš„æ–¹æ³•åŸºäº**SchrÃ¶dinger Bridge** (SB)ï¼Œç”¨äº**æ— é…å¯¹**å¯¹æ¯”åº¦è¿ç§»:

```python
# Forwardè¿‡ç¨‹: PD â†’ ä¸­é—´æ€ â†’ PDFs
X_t = (1-Î±)*X_{t-1} + Î±*G(X_{t-1}) + sqrt(Ï„*Î±*(1-Î±))*Îµ

# æŸå¤±å‡½æ•°
L = Î»_GAN * L_GAN      # åˆ¤åˆ«å™¨æŸå¤±
  + Î»_NCE * L_NCE       # å¯¹æ¯”å­¦ä¹ æŸå¤±
  + Î»_SB * L_SB         # SchrÃ¶dinger BridgeæŸå¤±
```

**L_SBçš„ç»„æˆ** (ç¬¬316-317è¡Œ):
```python
# èƒ½é‡é¡¹
ET_XY = E[f(X_t, G(X_t))] - log(âˆ‘exp(f(X_t, G'(X_t))))

# SBæŸå¤±
L_SB = -Ï„ * (T-t)/T * ET_XY           # èƒ½é‡å¼•å¯¼é¡¹
     + Ï„ * ||X_t - G(X_t)||Â²         # å‡æ–¹è¯¯å·®é¡¹
```

### å™ªéŸ³å¤„ç†çš„ç¼ºå¤±

**é—®é¢˜1: å‡è®¾æ•°æ®æ˜¯å¹²å‡€çš„**
```python
# mri_unaligned_dataset.py, line 356-362
if getattr(self.opt, 'mri_normalize_per_slice', False):
    tensor_max = tensor.max()
    if tensor_max > 0:
        tensor = tensor / tensor_max  # ç›´æ¥å½’ä¸€åŒ–
    tensor = (tensor - 0.5) / 0.5
```
- å½’ä¸€åŒ–æ—¶æ²¡æœ‰è€ƒè™‘å™ªéŸ³
- å™ªéŸ³è¢«åŒç­‰æ”¾å¤§

**é—®é¢˜2: SB losså¯¹å™ªéŸ³æ•æ„Ÿ**
```python
# sb_model.py, line 317
self.loss_SB += self.opt.tau * torch.mean((self.real_A_noisy - self.fake_B)**2)
```
- L2æŸå¤±ä¼šæƒ©ç½šæ‰€æœ‰å·®å¼‚ï¼ŒåŒ…æ‹¬å™ªéŸ³
- æ¨¡å‹è¢«è¿«æ‹Ÿåˆå™ªéŸ³æ¨¡å¼

**é—®é¢˜3: NCE losså­¦ä¹ å™ªéŸ³ç‰¹å¾**
```python
# sb_model.py, line 333-350
def calculate_NCE_loss(self, src, tgt):
    feat_q = self.netG(tgt, ...)  # ä»å«å™ªç›®æ ‡æå–ç‰¹å¾
    feat_k = self.netG(src, ...)  # ä»å«å™ªæºæå–ç‰¹å¾
    loss = InfoNCE(feat_q, feat_k)
```
- å¯¹æ¯”å­¦ä¹ ä¼šæŠŠå™ªéŸ³å½“ä½œ"é‰´åˆ«ç‰¹å¾"
- å¼ºåŒ–äº†å™ªéŸ³çš„ä¼ é€’

**é—®é¢˜4: æ— è‡ªé€‚åº”æœºåˆ¶**
- æ‰€æœ‰æ—¶é—´æ­¥tä½¿ç”¨ç›¸åŒçš„æŸå¤±æƒé‡
- æ²¡æœ‰æ ¹æ®å™ªéŸ³æ°´å¹³è°ƒæ•´è®­ç»ƒç­–ç•¥

---

## è§£å†³æ–¹æ¡ˆè®¨è®º

åŸºäºNilaçš„æ€æƒ³ï¼Œæˆ‘ä»¬å¯ä»¥ä»ä»¥ä¸‹å‡ ä¸ªæ–¹å‘è§£å†³ä½ çš„å™ªéŸ³é—®é¢˜:

### æ–¹æ¡ˆ1: å™ªéŸ³æ„ŸçŸ¥çš„å½’ä¸€åŒ– (Noise-Aware Normalization)

**æ€è·¯**: åœ¨æ•°æ®é¢„å¤„ç†æ—¶ä¼°è®¡å¹¶å‡å°‘å™ªéŸ³å½±å“

**å®ç°**:
```python
def _load_slice_with_denoising(self, file_path, key, norm_constants):
    with h5py.File(file_path, 'r') as handle:
        data = handle[key][...]

    # è®¡ç®—magnitude
    real, imag = data[..., 0], data[..., 1]
    magnitude = np.sqrt(real**2 + imag**2)

    # ä¼°è®¡å™ªéŸ³æ°´å¹³ (ä½¿ç”¨èƒŒæ™¯åŒºåŸŸ)
    # æ–¹æ³•1: Median Absolute Deviation
    noise_estimate = estimate_noise_mad(magnitude)

    # æ–¹æ³•2: ä½¿ç”¨Ricianå™ªéŸ³æ¨¡å‹
    # Ïƒ = sqrt(mean(backgroundÂ²))

    # ç¨³å¥å½’ä¸€åŒ– (ä½¿ç”¨percentileè€Œémax)
    p95 = np.percentile(magnitude, 95)
    magnitude_normalized = np.clip(magnitude / p95, 0, 1.5)

    # å­˜å‚¨å™ªéŸ³æ°´å¹³ç”¨äºåç»­å¤„ç†
    self.noise_levels[file_path] = noise_estimate

    return magnitude_normalized
```

**ä¼˜ç‚¹**:
- ç®€å•ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹
- å¯ä»¥ç«‹å³å®æ–½

**ç¼ºç‚¹**:
- ä»…å‡è½»é—®é¢˜ï¼Œæ— æ³•å®Œå…¨æ¶ˆé™¤
- å¯èƒ½æŸå¤±éƒ¨åˆ†ä¿¡å·ä¿¡æ¯

---

### æ–¹æ¡ˆ2: å™ªéŸ³æ°´å¹³è‡ªé€‚åº”çš„SBæŸå¤± (Nila-inspired Adaptive SB Loss)

**æ€è·¯**: æ¨¡ä»¿Nilaçš„è‡ªé€‚åº”ç­–ç•¥ï¼Œåœ¨ä¸åŒæ—¶é—´æ­¥è°ƒæ•´æŸå¤±æƒé‡

**æ ¸å¿ƒåŸç†**:
```
æ—©æœŸæ­¥éª¤(å¤§t): äººå·¥å™ªéŸ³Ïƒ_tå¤§ï¼Œå¯ä»¥ä¾èµ–é‡å»ºæŸå¤±
æ™šæœŸæ­¥éª¤(å°t): äººå·¥å™ªéŸ³Ïƒ_tå°ï¼Œåº”è¯¥å‡å°‘å¯¹å«å™ªæ•°æ®çš„æ‹Ÿåˆ
```

**å®ç°ä¿®æ”¹** (`sb_model.py`):
```python
def compute_G_loss(self):
    bs = self.real_A.size(0)
    tau = self.opt.tau
    t = self.time_idx[0].item()
    T = self.opt.num_timesteps

    # ä¼°è®¡å½“å‰æ—¶é—´æ­¥çš„å™ªéŸ³æ°´å¹³
    # tauæ§åˆ¶äººå·¥å™ªéŸ³: sigma_artificial = sqrt(tau * scale)
    current_step_ratio = t / T
    artificial_noise_level = np.sqrt(tau * current_step_ratio * (1 - current_step_ratio))

    # å‡è®¾æˆ‘ä»¬çŸ¥é“æ•°æ®å™ªéŸ³æ°´å¹³ (å¯ä»¥ä»æ•°æ®ä¸­ä¼°è®¡)
    data_noise_level = self.opt.data_noise_level  # ä¾‹å¦‚ 0.05

    # è‡ªé€‚åº”æƒé‡ (ç±»ä¼¼Nilaçš„lambda_t)
    if artificial_noise_level < data_noise_level:
        # å½“äººå·¥å™ªéŸ³å°äºæ•°æ®å™ªéŸ³æ—¶ï¼Œå‡å°‘é‡å»ºæŸå¤±æƒé‡
        noise_adaptive_weight = artificial_noise_level / data_noise_level
    else:
        noise_adaptive_weight = 1.0

    # === ä¿®æ”¹SBæŸå¤± ===
    if self.opt.lambda_SB > 0.0:
        XtXt_1 = torch.cat([self.real_A_noisy, self.fake_B], dim=1)
        XtXt_2 = torch.cat([self.real_A_noisy2, self.fake_B2], dim=1)

        bs = self.opt.batch_size
        ET_XY = self.netE(XtXt_1, self.time_idx, XtXt_1).mean() \
              - torch.logsumexp(self.netE(XtXt_1, self.time_idx, XtXt_2).reshape(-1), dim=0)

        self.loss_SB = -(T - t) / T * tau * ET_XY

        # ğŸ”¥ å…³é”®ä¿®æ”¹: åº”ç”¨å™ªéŸ³è‡ªé€‚åº”æƒé‡
        reconstruction_loss = torch.mean((self.real_A_noisy - self.fake_B)**2)
        self.loss_SB += noise_adaptive_weight * tau * reconstruction_loss

    # GANå’ŒNCEæŸå¤±ä¿æŒä¸å˜
    self.loss_G_GAN = ...
    self.loss_NCE = ...

    self.loss_G = self.loss_G_GAN + self.opt.lambda_SB * self.loss_SB \
                + self.opt.lambda_NCE * self.loss_NCE
    return self.loss_G
```

**ä¼˜ç‚¹**:
- ç›´æ¥å€Ÿé‰´Nilaçš„æ ¸å¿ƒæ€æƒ³
- ä¸æ”¹å˜ç½‘ç»œæ¶æ„
- ç†è®ºæœ‰æ®

**ç¼ºç‚¹**:
- éœ€è¦ä¼°è®¡æ•°æ®å™ªéŸ³æ°´å¹³Ïƒ_data
- å¯èƒ½éœ€è¦è°ƒæ•´è¶…å‚æ•°

---

### æ–¹æ¡ˆ3: å™ªéŸ³æ¡ä»¶åŒ–çš„ç”Ÿæˆå™¨ (Noise-Conditioned Generator)

**æ€è·¯**: è®©æ¨¡å‹æ˜¾å¼åœ°å­¦ä¹ å™ªéŸ³æ°´å¹³ï¼Œå¹¶åœ¨ç”Ÿæˆæ—¶å»é™¤å™ªéŸ³

**å®ç°**:

**3.1 æ‰©å±•è¾“å…¥** - æ·»åŠ å™ªéŸ³æ°´å¹³ä½œä¸ºæ¡ä»¶:
```python
# networks.py - ä¿®æ”¹ç”Ÿæˆå™¨è¾“å…¥
class NoisyResnetGenerator(nn.Module):
    def __init__(self, input_nc, output_nc, ...):
        # æ·»åŠ å™ªéŸ³åµŒå…¥å±‚
        self.noise_embed = nn.Sequential(
            nn.Linear(1, 256),
            nn.ReLU(),
            nn.Linear(256, 256)
        )

    def forward(self, x, time_idx, z, noise_level=None):
        # x: [B, C, H, W]
        # noise_level: [B, 1] ä¼°è®¡çš„å™ªéŸ³æ ‡å‡†å·®

        if noise_level is not None:
            # åµŒå…¥å™ªéŸ³æ°´å¹³
            noise_emb = self.noise_embed(noise_level)  # [B, 256]
            # ä¸æ—¶é—´åµŒå…¥ç»“åˆ
            cond = time_emb + noise_emb
        else:
            cond = time_emb

        # ... åç»­ç½‘ç»œå¤„ç†
```

**3.2 æ•°æ®åŠ è½½** - ä¼°è®¡å¹¶ä¼ é€’å™ªéŸ³æ°´å¹³:
```python
# mri_unaligned_dataset.py
def _estimate_noise_level(self, magnitude):
    """
    ä¼°è®¡å›¾åƒå™ªéŸ³æ°´å¹³
    æ–¹æ³•: Median Absolute Deviation (MAD)
    """
    # å‡è®¾èƒŒæ™¯å™ªéŸ³ä¸ºé«˜æ–¯åˆ†å¸ƒ
    # ä½¿ç”¨è¾ƒä½çš„åƒç´ å€¼ä¼°è®¡å™ªéŸ³
    background = magnitude[magnitude < np.percentile(magnitude, 20)]
    if len(background) > 100:
        noise_std = 1.4826 * np.median(np.abs(background - np.median(background)))
    else:
        # å¤‡é€‰: ä½¿ç”¨Laplacianç®—å­ä¼°è®¡
        laplacian = cv2.Laplacian(magnitude, cv2.CV_64F)
        noise_std = np.std(laplacian) / np.sqrt(2)

    return noise_std

def __getitem__(self, index):
    # ... åŠ è½½æ•°æ®
    A_tensor = self._load_slice(A_path, A_key, self.norm_constants_A)
    B_tensor = self._load_slice(B_path, B_key, self.norm_constants_B)

    # ä¼°è®¡å™ªéŸ³æ°´å¹³
    A_magnitude = torch.sqrt(A_tensor[0]**2 + A_tensor[1]**2)
    B_magnitude = torch.sqrt(B_tensor[0]**2 + B_tensor[1]**2)

    noise_A = self._estimate_noise_level(A_magnitude.numpy())
    noise_B = self._estimate_noise_level(B_magnitude.numpy())

    return {
        'A': A_tensor,
        'B': B_tensor,
        'noise_A': torch.tensor([noise_A], dtype=torch.float32),
        'noise_B': torch.tensor([noise_B], dtype=torch.float32),
        'A_paths': a_path_label,
        'B_paths': b_path_label
    }
```

**3.3 è®­ç»ƒä¿®æ”¹**:
```python
# sb_model.py
def set_input(self, input, input2=None):
    AtoB = self.opt.direction == 'AtoB'
    self.real_A = input['A' if AtoB else 'B'].to(self.device)
    self.real_B = input['B' if AtoB else 'A'].to(self.device)

    # è·å–å™ªéŸ³æ°´å¹³
    self.noise_A = input.get('noise_A', None)
    self.noise_B = input.get('noise_B', None)
    if self.noise_A is not None:
        self.noise_A = self.noise_A.to(self.device)
    if self.noise_B is not None:
        self.noise_B = self.noise_B.to(self.device)

def forward(self):
    # ... ç”ŸæˆX_t

    # ä¼ é€’å™ªéŸ³æ°´å¹³ç»™ç”Ÿæˆå™¨
    self.fake_B = self.netG(
        self.real_A_noisy,
        self.time_idx,
        z_in[:bs],
        noise_level=self.noise_A
    )
```

**ä¼˜ç‚¹**:
- æ¨¡å‹å¯ä»¥å­¦ä¹ é’ˆå¯¹ä¸åŒå™ªéŸ³æ°´å¹³çš„å»å™ªç­–ç•¥
- çµæ´»ï¼Œé€‚ç”¨äºvarying noise levels

**ç¼ºç‚¹**:
- éœ€è¦å‡†ç¡®çš„å™ªéŸ³ä¼°è®¡
- å¢åŠ æ¨¡å‹å¤æ‚åº¦
- éœ€è¦é‡æ–°è®­ç»ƒ

---

### æ–¹æ¡ˆ4: ä¸¤é˜¶æ®µæ–¹æ³• - å»å™ª + è¿ç§» (Two-Stage: Denoise then Transfer)

**æ€è·¯**: å°†é—®é¢˜åˆ†è§£ä¸ºä¸¤ä¸ªå­é—®é¢˜
1. é˜¶æ®µ1: å»å™ª (åœ¨å„è‡ªåŸŸå†…)
2. é˜¶æ®µ2: å¯¹æ¯”åº¦è¿ç§» (åœ¨å»å™ªåçš„æ•°æ®ä¸Š)

**å®ç°**:

**é˜¶æ®µ1: è‡ªç›‘ç£å»å™ª** (å¯ä»¥ä½¿ç”¨Nilaæˆ–å…¶ä»–å»å™ªæ–¹æ³•)
```python
# Option A: ä½¿ç”¨Nilaçš„diffusionå»å™ª
# - è®­ç»ƒä¸€ä¸ªunconditional diffusion modelåœ¨PDåŸŸ
# - è®­ç»ƒä¸€ä¸ªunconditional diffusion modelåœ¨PDFsåŸŸ
# - æ¨ç†æ—¶åšdenoising

# Option B: ä½¿ç”¨ä¼ ç»Ÿå»å™ªæ–¹æ³•
# - BM3D
# - Non-local means
# - Deep learningå»å™ª (Noise2Noise, DnCNNç­‰)

# Option C: Noise2Voidé£æ ¼è‡ªç›‘ç£
class SelfSupervisedDenoiser(nn.Module):
    """
    åˆ©ç”¨ç›²ç‚¹ç½‘ç»œ (Blind-spot network) è¿›è¡Œè‡ªç›‘ç£å»å™ª
    ä¸éœ€è¦å¹²å‡€æ•°æ®ä½œä¸ºground truth
    """
    def __init__(self):
        super().__init__()
        # U-Net with blind-spot masking

    def forward(self, noisy_input, mask):
        # mask: éšæœºé®æŒ¡ä¸€äº›åƒç´ 
        # è®­ç»ƒç›®æ ‡: ä»å‘¨å›´åƒç´ é¢„æµ‹è¢«é®æŒ¡åƒç´ 
        return denoised
```

**é˜¶æ®µ2: åœ¨å»å™ªæ•°æ®ä¸Šè®­ç»ƒUNSB**
```python
# é¢„å¤„ç†: ä½¿ç”¨è®­ç»ƒå¥½çš„å»å™ªå™¨
denoiser_A = load_denoiser('checkpoints/denoiser_A.pth')
denoiser_B = load_denoiser('checkpoints/denoiser_B.pth')

def _load_slice(self, file_path, key, norm_constants):
    tensor = ... # åŸå§‹åŠ è½½

    # åº”ç”¨å»å™ª
    with torch.no_grad():
        if 'domainA' in file_path:
            tensor = denoiser_A(tensor.unsqueeze(0)).squeeze(0)
        else:
            tensor = denoiser_B(tensor.unsqueeze(0)).squeeze(0)

    return tensor

# ç„¶åæ­£å¸¸è®­ç»ƒUNSB
```

**ä¼˜ç‚¹**:
- æ¨¡å—åŒ–ï¼Œæ¯ä¸ªé˜¶æ®µç‹¬ç«‹ä¼˜åŒ–
- å»å™ªæ–¹æ³•å¯ä»¥é€‰æ‹©æœ€æˆç†Ÿçš„æŠ€æœ¯
- å¯è§£é‡Šæ€§å¼º

**ç¼ºç‚¹**:
- ä¸¤é˜¶æ®µpipelineå¤æ‚
- å»å™ªå¯èƒ½æŸå¤±éƒ¨åˆ†ä¿¡æ¯
- éœ€è¦æ›´å¤šè®­ç»ƒæ—¶é—´

---

### æ–¹æ¡ˆ5: è”åˆå»å™ªä¸è¿ç§» (Joint Denoising and Translation)

**æ€è·¯**: åœ¨SBæ¡†æ¶å†…åŒæ—¶å­¦ä¹ å»å™ªå’Œå¯¹æ¯”åº¦è¿ç§»

**æ ¸å¿ƒæ€æƒ³**:
å°†ç›®æ ‡å®šä¹‰ä¸º:
```
è¾“å…¥: å«å™ªPD (x_noisy)
è¾“å‡º: å¹²å‡€PDFs (y_clean)

è€Œä¸æ˜¯:
è¾“å…¥: å¹²å‡€PD (x_clean)
è¾“å‡º: å¹²å‡€PDFs (y_clean)
```

**å®ç°** - ä¿®æ”¹è®­ç»ƒç›®æ ‡:

**5.1 å™ªéŸ³å¢å¼ºè®­ç»ƒ**:
```python
# sb_model.py - forward()
def forward(self):
    # åŸå§‹: ä»cleanæ•°æ®å¼€å§‹
    # X_0 = self.real_A

    # ä¿®æ”¹: æ¨¡æ‹Ÿå«å™ªè¾“å…¥
    if self.isTrain and self.opt.noise_augmentation:
        # åœ¨çœŸå®æ•°æ®ä¸Šæ·»åŠ é¢å¤–çš„å™ªéŸ³ (data augmentation)
        synthetic_noise_level = np.random.uniform(0, self.opt.max_noise_std)
        noise = torch.randn_like(self.real_A) * synthetic_noise_level
        X_0 = self.real_A + noise
    else:
        X_0 = self.real_A

    # Bridgeè¿‡ç¨‹: X_0 (noisy PD) â†’ ... â†’ X_T â‰ˆ clean PDFs
    for t in range(self.time_idx.int().item() + 1):
        # ... SB forward pass
        X_{t+1} = self.netG(X_t, t, z)
```

**5.2 å¤šå°ºåº¦å»å™ªæŸå¤±**:
```python
def compute_G_loss(self):
    # åŸæœ‰æŸå¤±
    self.loss_G_GAN = ...
    self.loss_NCE = ...
    self.loss_SB = ...

    # ğŸ”¥ æ·»åŠ å»å™ªæ­£åˆ™åŒ–
    if self.opt.lambda_denoise > 0.0:
        # å‡è®¾æˆ‘ä»¬æœ‰ä¸€äº›é…å¯¹çš„å«å™ª/å»å™ªæ•°æ® (å¯ä»¥ç”¨ä¼ ç»Ÿæ–¹æ³•ç”Ÿæˆ)
        # æˆ–è€…ä½¿ç”¨è‡ªç›‘ç£ç›®æ ‡

        # Option 1: å¦‚æœæœ‰å°‘é‡é…å¯¹æ•°æ®
        if hasattr(self, 'clean_reference'):
            # æ—©æœŸæ­¥éª¤åº”è¯¥å»å™ª
            early_output = self.netG(self.real_A_noisy,
                                     time_idx=torch.zeros_like(self.time_idx),
                                     z=z)
            self.loss_denoise = F.l1_loss(early_output, self.clean_reference)

        # Option 2: è‡ªç›‘ç£ - å™ªéŸ³ä¸€è‡´æ€§
        else:
            # åŒä¸€ä¸ªå«å™ªè¾“å…¥ + ä¸åŒå™ªéŸ³å®ç° â†’ åº”è¯¥ç»™å‡ºç›¸ä¼¼çš„è¾“å‡º
            X_t_1 = self.real_A_noisy  # å«å™ª + SBå™ªéŸ³ç‰ˆæœ¬1
            X_t_2 = self.real_A_noisy2 # ç›¸åŒå«å™ªè¾“å…¥ + SBå™ªéŸ³ç‰ˆæœ¬2

            out_1 = self.netG(X_t_1, self.time_idx, z1)
            out_2 = self.netG(X_t_2, self.time_idx, z2)

            # è¾“å‡ºåº”è¯¥ä¸€è‡´ (é™¤äº†å™ªéŸ³å¼•èµ·çš„éšæœºæ€§)
            self.loss_denoise = F.mse_loss(out_1, out_2)
    else:
        self.loss_denoise = 0.0

    self.loss_G = (self.loss_G_GAN +
                   self.opt.lambda_SB * self.loss_SB +
                   self.opt.lambda_NCE * self.loss_NCE +
                   self.opt.lambda_denoise * self.loss_denoise)
    return self.loss_G
```

**5.3 å™ªéŸ³ä¼°è®¡ç½‘ç»œ** (å¯é€‰):
```python
class NoiseEstimator(nn.Module):
    """
    ä¼°è®¡å›¾åƒå™ªéŸ³æ°´å¹³çš„ç½‘ç»œ
    å¯ä»¥ä¸ä¸»ç½‘ç»œè”åˆè®­ç»ƒ
    """
    def __init__(self):
        super().__init__()
        # ç®€å•çš„CNN
        self.conv_layers = nn.Sequential(
            nn.Conv2d(2, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(64, 1),
            nn.Softplus()  # ç¡®ä¿è¾“å‡ºä¸ºæ­£
        )

    def forward(self, x):
        return self.conv_layers(x)  # è¾“å‡º: å™ªéŸ³æ ‡å‡†å·®ä¼°è®¡

# åœ¨SBModelä¸­æ·»åŠ 
self.netN = NoiseEstimator().to(self.device)

# è®­ç»ƒæ—¶
estimated_noise = self.netN(self.real_A)
# ä½¿ç”¨ä¼°è®¡çš„å™ªéŸ³æ°´å¹³æŒ‡å¯¼å»å™ªè¿‡ç¨‹
```

**ä¼˜ç‚¹**:
- ç«¯åˆ°ç«¯è®­ç»ƒ
- ç†è®ºä¸Šæœ€ä¼˜ (åŒæ—¶ä¼˜åŒ–ä¸¤ä¸ªç›®æ ‡)
- æ— éœ€é¢å¤–çš„é¢„å¤„ç†pipeline

**ç¼ºç‚¹**:
- è®­ç»ƒéš¾åº¦å¤§
- éœ€è¦ç²¾å¿ƒè®¾è®¡æŸå¤±å‡½æ•°å¹³è¡¡
- å¯èƒ½éœ€è¦æ›´å¤šæ•°æ®

---

## æ¨èå®æ–½è·¯å¾„

åŸºäºä½ çš„å…·ä½“æƒ…å†µï¼Œæˆ‘å»ºè®®æŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§å°è¯•:

### ğŸ¥‡ ä¼˜å…ˆçº§1: æ–¹æ¡ˆ2 - å™ªéŸ³æ°´å¹³è‡ªé€‚åº”çš„SBæŸå¤±
**ç†ç”±**:
- æœ€æ¥è¿‘Nilaçš„æ ¸å¿ƒæ€æƒ³
- å®ç°ç®€å•ï¼Œä¿®æ”¹é‡å°
- ç†è®ºåŸºç¡€æ‰å®
- å¯ä»¥å¿«é€ŸéªŒè¯æ•ˆæœ

**å®æ–½æ­¥éª¤**:
1. ä¼°è®¡æ•°æ®å™ªéŸ³æ°´å¹³ (ä½¿ç”¨èƒŒæ™¯åŒºåŸŸæˆ–MADæ–¹æ³•)
2. åœ¨`compute_G_loss()`ä¸­æ·»åŠ å™ªéŸ³è‡ªé€‚åº”æƒé‡
3. æ·»åŠ å‘½ä»¤è¡Œå‚æ•°`--data_noise_level`
4. è®­ç»ƒå¹¶å¯¹æ¯”ç»“æœ

**å®æ–½æ—¶é—´**: 1-2å¤©

---

### ğŸ¥ˆ ä¼˜å…ˆçº§2: æ–¹æ¡ˆ1 + æ–¹æ¡ˆ2 ç»„åˆ
**ç†ç”±**:
- æ•°æ®é¢„å¤„ç†æ”¹è¿› (æ–¹æ¡ˆ1) å¯ä»¥ç«‹å³å¸¦æ¥æå‡
- ç»“åˆè‡ªé€‚åº”æŸå¤± (æ–¹æ¡ˆ2) è¿›ä¸€æ­¥ä¼˜åŒ–
- é£é™©ä½ï¼Œæ”¶ç›Šç¨³å®š

**å®æ–½æ­¥éª¤**:
1. ä¿®æ”¹`_load_slice()`ä½¿ç”¨percentileå½’ä¸€åŒ–
2. æ·»åŠ å™ªéŸ³ä¼°è®¡å¹¶å­˜å‚¨
3. å®æ–½æ–¹æ¡ˆ2çš„è‡ªé€‚åº”æŸå¤±
4. å¯¹æ¯”ablation studyæ•ˆæœ

**å®æ–½æ—¶é—´**: 2-3å¤©

---

### ğŸ¥‰ ä¼˜å…ˆçº§3: æ–¹æ¡ˆ3 - å™ªéŸ³æ¡ä»¶åŒ–ç”Ÿæˆå™¨ (å¦‚æœå‰ä¸¤ä¸ªæ•ˆæœä¸å¤Ÿ)
**ç†ç”±**:
- æ›´å¼ºå¤§çš„å»ºæ¨¡èƒ½åŠ›
- å¯ä»¥å¤„ç†varying noise levels
- é€‚åˆé•¿æœŸç ”ç©¶

**å®æ–½æ­¥éª¤**:
1. å®ç°å™ªéŸ³ä¼°è®¡å‡½æ•°
2. ä¿®æ”¹æ•°æ®åŠ è½½å™¨è¿”å›å™ªéŸ³æ°´å¹³
3. æ‰©å±•ç”Ÿæˆå™¨æ·»åŠ å™ªéŸ³åµŒå…¥
4. é‡æ–°è®­ç»ƒæ¨¡å‹

**å®æ–½æ—¶é—´**: 5-7å¤©

---

### ğŸ”¬ å®éªŒéªŒè¯æ–¹æ¡ˆ

æ— è®ºé€‰æ‹©å“ªä¸ªæ–¹æ¡ˆï¼Œéƒ½åº”è¯¥è¿›è¡Œä»¥ä¸‹éªŒè¯:

**1. å®šé‡è¯„ä¼°**:
```python
# åœ¨testæ—¶è®¡ç®—ä»¥ä¸‹æŒ‡æ ‡
metrics = {
    'PSNR': psnr(generated, reference),
    'SSIM': ssim(generated, reference),
    'Noise_Level': estimate_noise(generated),
    'SNR': calculate_snr(generated)
}
```

**2. å¯¹æ¯”å®éªŒ**:
- Baseline: å½“å‰UNSB (æ— å™ªéŸ³å¤„ç†)
- Proposed: åŠ å…¥å™ªéŸ³å¤„ç†çš„UNSB
- Upper Bound: åœ¨äººå·¥å»å™ªåçš„æ•°æ®ä¸Šè®­ç»ƒçš„UNSB

**3. Ablation Study**:
- åªç”¨è‡ªé€‚åº”æƒé‡
- åªç”¨ç¨³å¥å½’ä¸€åŒ–
- ä¸¤è€…ç»“åˆ

**4. å¯è§†åŒ–**:
```python
# util/mri_visualize.py
def visualize_noise_reduction(original, denoised, transferred):
    """
    å¯è§†åŒ–:
    - åŸå§‹PD (å«å™ª)
    - å»å™ªåPD
    - è¿ç§»çš„PDFs
    - çœŸå®PDFs (å¦‚æœæœ‰)
    - å™ªéŸ³å›¾ (original - denoised)
    """
    fig, axes = plt.subplots(1, 5, figsize=(20, 4))
    # ... ç»˜å›¾ä»£ç 
```

---

## é¢å¤–å»ºè®®

### 1. æ•°æ®è´¨é‡è¯„ä¼°
åœ¨å®æ–½ä»»ä½•æ–¹æ¡ˆå‰ï¼Œå…ˆè¯„ä¼°æ•°æ®å™ªéŸ³æ°´å¹³:
```python
# è„šæœ¬: analyze_noise.py
import h5py
import numpy as np
from pathlib import Path

def estimate_noise_mad(image):
    """ä½¿ç”¨MADä¼°è®¡å™ªéŸ³"""
    background = image[image < np.percentile(image, 20)]
    return 1.4826 * np.median(np.abs(background - np.median(background)))

# éå†æ‰€æœ‰æ•°æ®
for h5_file in Path('datasets/trainA').glob('*.h5'):
    with h5py.File(h5_file, 'r') as f:
        for key in f.keys():
            if key.startswith('slices_'):
                data = f[key][...]
                mag = np.sqrt(data[...,0]**2 + data[...,1]**2)
                noise = estimate_noise_mad(mag)
                print(f"{h5_file.name}/{key}: Ïƒ = {noise:.4f}")
```

### 2. è€ƒè™‘Ricianå™ªéŸ³ç‰¹æ€§
MRI magnitudeæ•°æ®çš„å™ªéŸ³éµå¾ª**Ricianåˆ†å¸ƒ**ï¼Œè€Œéé«˜æ–¯åˆ†å¸ƒ:
```
åœ¨ä½SNRåŒºåŸŸ: å™ªéŸ³ä½¿magnitudeå€¼åé«˜ (noise floor)
åœ¨é«˜SNRåŒºåŸŸ: è¿‘ä¼¼é«˜æ–¯åˆ†å¸ƒ
```

å¯ä»¥è€ƒè™‘ä½¿ç”¨Ricianå™ªéŸ³æ¨¡å‹:
```python
def rician_loss(pred, target, sigma):
    """
    Ricianå™ªéŸ³æ„ŸçŸ¥çš„æŸå¤±å‡½æ•°
    target ~ Rician(pred, sigma)
    """
    # è´Ÿå¯¹æ•°ä¼¼ç„¶
    loss = -torch.log(
        target / (sigma**2) * torch.exp(-(target**2 + pred**2) / (2*sigma**2))
        * torch.i0(target * pred / sigma**2)
    )
    return loss.mean()
```

### 3. åˆ©ç”¨kç©ºé—´ä¿¡æ¯
å¦‚æœä½ æœ‰åŸå§‹kç©ºé—´æ•°æ®ï¼Œå¯ä»¥:
- ç›´æ¥ä¼°è®¡kç©ºé—´å™ªéŸ³ (æ›´å‡†ç¡®)
- åœ¨kç©ºé—´åšä½é€šæ»¤æ³¢å»å™ª
- ä½¿ç”¨Nilaçš„å®Œæ•´æ–¹æ³• (kç©ºé—´æ•°æ®ä¸€è‡´æ€§)

---

## æ€»ç»“

ä½ çš„é—®é¢˜æ ¸å¿ƒåœ¨äº: **UNSBåœ¨æ— é…å¯¹è®¾ç½®ä¸‹å­¦ä¹ äº†å™ªéŸ³æ¨¡å¼è€Œéçº¯å‡€çš„å¯¹æ¯”åº¦æ˜ å°„**

Nilaçš„å¯ç¤º: **å™ªéŸ³æ°´å¹³è‡ªé€‚åº”æ˜¯å…³é”®** - åœ¨ä¸åŒçš„å¤„ç†é˜¶æ®µåº”è¯¥ä½¿ç”¨ä¸åŒå¼ºåº¦çš„çº¦æŸ

æ¨èè·¯å¾„:
1. ğŸ¯ **ç«‹å³å®æ–½**: æ–¹æ¡ˆ2 (è‡ªé€‚åº”SBæŸå¤±) + æ”¹è¿›çš„å½’ä¸€åŒ–
2. ğŸ”¬ **å®éªŒéªŒè¯**: å®šé‡è¯„ä¼°å™ªéŸ³å‡å°‘å’Œè¿ç§»è´¨é‡
3. ğŸš€ **é•¿æœŸä¼˜åŒ–**: å¦‚æœæ•ˆæœä¸å¤Ÿï¼Œè€ƒè™‘æ–¹æ¡ˆ3 (å™ªéŸ³æ¡ä»¶åŒ–) æˆ–æ–¹æ¡ˆ4 (ä¸¤é˜¶æ®µ)

å…³é”®å‚æ•°:
- `data_noise_level`: éœ€è¦ä»æ•°æ®ä¸­ä¼°è®¡ (å»ºè®®0.01-0.1èŒƒå›´)
- `adaptive_weight_schedule`: çº¿æ€§è¡°å‡ vs æŒ‡æ•°è¡°å‡
- `lambda_SB`: å¯èƒ½éœ€è¦é‡æ–°è°ƒæ•´ä»¥å¹³è¡¡è‡ªé€‚åº”æƒé‡

æˆ‘å¯ä»¥å¸®ä½ å®ç°ä»»ä½•ä¸€ä¸ªæ–¹æ¡ˆçš„å…·ä½“ä»£ç ã€‚ä½ æƒ³ä»å“ªä¸ªæ–¹æ¡ˆå¼€å§‹ï¼Ÿ
