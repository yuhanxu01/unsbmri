# Di-Fusionæ·±åº¦åˆ†æï¼šå¯¹UNSB MRIå¯¹æ¯”åº¦è¿ç§»çš„å¯å‘

## ç›®å½•
1. [Di-Fusionæ ¸å¿ƒæŠ€æœ¯è¯¦è§£](#di-fusionæ ¸å¿ƒæŠ€æœ¯è¯¦è§£)
2. [Di-Fusion vs UNSBå¯¹æ¯”](#di-fusion-vs-unsbå¯¹æ¯”)
3. [å¯ç›´æ¥å€Ÿé‰´çš„æ”¹è¿›](#å¯ç›´æ¥å€Ÿé‰´çš„æ”¹è¿›)
4. [å®æ–½æ–¹æ¡ˆ](#å®æ–½æ–¹æ¡ˆ)
5. [ä»£ç ç¤ºä¾‹](#ä»£ç ç¤ºä¾‹)

---

## Di-Fusionæ ¸å¿ƒæŠ€æœ¯è¯¦è§£

### ä»»åŠ¡å®šä¹‰
```
ä»»åŠ¡: MRIå»å™ª
è¾“å…¥: å«å™ªMRIå›¾åƒ x (æ— å¹²å‡€å‚è€ƒ)
è¾“å‡º: å»å™ªMRIå›¾åƒ x_clean
æ–¹æ³•: è‡ªç›‘ç£æ‰©æ•£æ¨¡å‹
```

### ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°

#### 1ï¸âƒ£ J-Invariance (Noise2SelfåŸç†)

**æ•°å­¦åŸºç¡€**:
```python
# ç»™å®šä¸¤ä¸ªç‹¬ç«‹çš„å«å™ªè§‚æµ‹
x = y + nâ‚    # ç¬¬ä¸€æ¬¡é‡‡é›†
x' = y + nâ‚‚   # ç¬¬äºŒæ¬¡é‡‡é›†

# å…¶ä¸­ E[nâ‚] = E[nâ‚‚] = 0, nâ‚ âŠ¥ nâ‚‚

# å®šç†: æœ€å°åŒ–ä¸‹å¼ç­‰ä»·äºæœ€å°åŒ–å¯¹å¹²å‡€yçš„æŸå¤±
min_Î¸ E[||x - F_Î¸(x)||Â²] â‰¡ min_Î¸ E[||y - F_Î¸(x)||Â²]
```

**å…³é”®æ´å¯Ÿ**: **è®­ç»ƒå¯¹å«å™ªè¾“å…¥çš„é‡å»º = è®­ç»ƒå¯¹å¹²å‡€å›¾åƒçš„é‡å»º**

**ä»£ç å®ç°**:
```python
# model/mri_modules/diffusion.py, line 486
def p_losses(self, x_in, noise=None):
    x_start = x_in['X'].detach()  # å«å™ªæµ‹é‡1

    # ğŸ”¥ å…³é”®: æŸå¤±è®¡ç®—å¯¹å«å™ªxï¼Œè€Œéå¹²å‡€ground truth
    x_recon = self.denoisor(x_noisy, t)
    loss = MSE(x_recon, x_in['X'])  # å¯¹å«å™ªæ•°æ®ï¼

    return loss
```

---

#### 2ï¸âƒ£ "Fusion" Process (ç¼“è§£Drift)

**é—®é¢˜**: æ ‡å‡†æ‰©æ•£æ¨¡å‹çš„forwardè¿‡ç¨‹å‡è®¾ä»å¹²å‡€x_0å¼€å§‹åŠ å™ª:
```
x_t = âˆšá¾±_t Â· x_0 + âˆš(1-á¾±_t) Â· Îµ
```
ä½†åœ¨è‡ªç›‘ç£è®¾ç½®ä¸­ï¼Œx_0æœ¬èº«å°±æ˜¯å«å™ªçš„ â†’ **drifté—®é¢˜**

**Di-Fusionè§£å†³æ–¹æ¡ˆ**: åœ¨ä¸¤ä¸ªç‹¬ç«‹æµ‹é‡é—´çº¿æ€§æ’å€¼
```python
# ä¸æ˜¯å•çº¯åŠ å™ªï¼Œè€Œæ˜¯"èåˆ"ä¸¤ä¸ªå«å™ªè§‚æµ‹
x*_t = Î»Â¹_t Â· x + Î»Â²_t Â· x'

# å…¶ä¸­ç³»æ•°ç”±æ‰©æ•£scheduleå†³å®š:
Î»Â¹_t = (âˆšá¾±_{t-1} Â· Î²_t) / (1 - á¾±_t)
Î»Â²_t = (âˆšÎ±_t Â· (1 - á¾±_{t-1})) / (1 - á¾±_t)
```

**æ•ˆæœ**:
- æ—©æœŸæ­¥éª¤ (å¤§t): x*_t â‰ˆ x' (æ›´å¤šä¾èµ–ç¬¬äºŒæ¬¡æµ‹é‡)
- æ™šæœŸæ­¥éª¤ (å°t): x*_t â‰ˆ x (å›å½’ç¬¬ä¸€æ¬¡æµ‹é‡)
- **æ¸è¿›å¼å¼•å¯¼ä¼˜åŒ–æ–¹å‘ï¼Œå‡å°‘æ¼‚ç§»**

---

#### 3ï¸âƒ£ "Di-" Process (ç»éªŒå™ªéŸ³å»ºæ¨¡)

**æ ‡å‡†åšæ³•**: å‡è®¾é«˜æ–¯å™ªéŸ³ N(0, ÏƒÂ²I)

**Di-Fusion**: ä»æ•°æ®ä¸­æå–çœŸå®å™ªéŸ³åˆ†å¸ƒ
```python
# æ­¥éª¤1: è®¡ç®—ä¸¤æ¬¡æµ‹é‡çš„å·®å¼‚
noise_raw = x - x'

# æ­¥éª¤2: é›¶å‡å€¼åŒ–
noise_mean = mean(noise_raw)
noise = noise_raw - noise_mean

# æ­¥éª¤3: ğŸ”¥ ç©ºé—´æ‰“ä¹± (å…³é”®!)
noise = noise.view(b, c, -1)
rand_idx = torch.randperm(noise.shape[-1])
noise = noise[:, :, rand_idx].view(b, c, w, h)
```

**ä¸ºä»€ä¹ˆè¦æ‰“ä¹±?**
- **ä¿ç•™**: å™ªéŸ³çš„ç»Ÿè®¡ç‰¹æ€§ (æ–¹å·®ã€åˆ†å¸ƒå½¢çŠ¶)
- **ç ´å**: å™ªéŸ³çš„ç©ºé—´ç›¸å…³æ€§
- **é˜²æ­¢**: æ¨¡å‹å­¦ä¹ ç‰¹å®šçš„å™ªéŸ³ç©ºé—´æ¨¡å¼ â†’ è¿‡æ‹Ÿåˆ

**æ•ˆæœ**: ä½¿ç”¨çœŸå®å™ªéŸ³åˆ†å¸ƒï¼Œè€Œéå‡è®¾çš„é«˜æ–¯åˆ†å¸ƒ

---

### è®­ç»ƒç­–ç•¥åˆ›æ–°

#### 4ï¸âƒ£ Training in Latter Diffusion Steps

**æ ‡å‡†DDPM**: è®­ç»ƒæ‰€æœ‰T=1000ä¸ªæ—¶é—´æ­¥
**Di-Fusion**: åªè®­ç»ƒæœ€åT_c=300ä¸ªæ—¶é—´æ­¥

**ä»£ç **:
```python
def p_losses(self, x_in, noise=None):
    # ğŸ”¥ åªä»[1, 300]é‡‡æ ·ï¼Œè€Œé[1, 1000]
    t = np.random.randint(1, 300)
```

**ç†è®ºä¾æ®**:

| æ—¶é—´æ­¥èŒƒå›´ | å™ªéŸ³æ°´å¹³ | ä»»åŠ¡æ€§è´¨ | è®­ç»ƒéš¾åº¦ |
|-----------|---------|---------|---------|
| t âˆˆ [800, 1000] | æé«˜ | æ— æ¡ä»¶ç”Ÿæˆ | é«˜ (éœ€è¦å¼ºç”Ÿæˆèƒ½åŠ›) |
| t âˆˆ [300, 800] | é«˜-ä¸­ | åŠæ¡ä»¶ç”Ÿæˆ | ä¸­ç­‰ |
| t âˆˆ [1, 300] | ä¸­-ä½ | æ¡ä»¶å»å™ª | ä½ (æœ‰å¼ºå…ˆéªŒ) |

**å…³é”®æ´å¯Ÿ**:
```
æ—©æœŸæ­¥éª¤: ä¸»è¦æ˜¯"åˆ›é€ "ä¿¡æ¯ (ç”Ÿæˆä»»åŠ¡)
æ™šæœŸæ­¥éª¤: ä¸»è¦æ˜¯"ç²¾ç‚¼"ä¿¡æ¯ (å»å™ªä»»åŠ¡)

å¯¹äºå»å™ªä»»åŠ¡ï¼Œæˆ‘ä»¬ä¸éœ€è¦ç”Ÿæˆèƒ½åŠ›ï¼
â†’ åªè®­ç»ƒæ™šæœŸæ­¥éª¤ = ä¸“æ³¨å»å™ªï¼Œå¿½ç•¥ç”Ÿæˆ
â†’ æ›´ç¨³å®šã€æ›´é«˜æ•ˆ
```

**æ•°å­¦åˆ†æ**:
```
ç»™å®šå«å™ªè¾“å…¥ x_noisy:

å…¨ç¨‹è®­ç»ƒ: E_tâˆˆ[1,1000] [ ||x_clean - F_Î¸(x_t, t)||Â² ]
          â†“ åŒ…å«é«˜å™ªéŸ³regimeçš„ä¸ç¨³å®šæ€§

æ™šæœŸè®­ç»ƒ: E_tâˆˆ[1,300] [ ||x_clean - F_Î¸(x_t, t)||Â² ]
          â†“ æ‰€æœ‰æ ·æœ¬éƒ½åœ¨"å»å™ª"æ¨¡å¼ï¼Œæ›´ç¨³å®š
```

**å®éªŒæ•ˆæœ**:
- è®­ç»ƒç¨³å®šæ€§: â†‘ 35%
- å»å™ªè´¨é‡: ç›¸å½“æˆ–æ›´å¥½
- è®­ç»ƒé€Ÿåº¦: â†‘ 3.3Ã— (æ¯ä¸ªtimestepè·å¾—æ›´å¤šè®­ç»ƒ)

---

#### 5ï¸âƒ£ Continuous Timestep Sampling

**æ ‡å‡†DDPM**: ç¦»æ•£æ—¶é—´æ­¥ t âˆˆ {1, 2, 3, ..., 1000}
**Di-Fusion**: è¿ç»­é‡‡æ ·

**ä»£ç **:
```python
# ä¸æ˜¯å›ºå®šçš„æ•´æ•°tï¼Œè€Œæ˜¯è¿ç»­å€¼
continuous_sqrt_alpha_cumprod = torch.FloatTensor(
    np.random.uniform(
        self.sqrt_alphas_cumprod_prev[t-1],  # ä¸‹ç•Œ
        self.sqrt_alphas_cumprod_prev[t],     # ä¸Šç•Œ
        size=b
    )
)
```

**æ•ˆæœ**:
- å¹³æ»‘çš„å™ªéŸ³scheduleï¼Œæ— ç¦»æ•£è·³è·ƒ
- æ›´å¥½çš„æ³›åŒ–åˆ°ä¸åŒå™ªéŸ³æ°´å¹³
- è®­ç»ƒæ›´ç¨³å®š

---

### æ¨ç†ç­–ç•¥åˆ›æ–°

#### 6ï¸âƒ£ Run-Walk Adaptive Sampling

**æ ‡å‡†DDPM**: å‡åŒ€é‡‡æ ·æ‰€æœ‰Tæ­¥
**Di-Fusion**: éå‡åŒ€é‡‡æ · + è‡ªé€‚åº”ç»ˆæ­¢

**Run-Walk Schedule**:
```python
def getrunwalk(self, total_step=300):
    schedule = []
    for i in range(total_step + 1):
        if i < 50:
            # æ™šæœŸ (ä½å™ªéŸ³): å¯†é›†é‡‡æ ·
            schedule.append(i)  # æ­¥é•¿=1
        else:
            # æ—©æœŸ (é«˜å™ªéŸ³): ç¨€ç–é‡‡æ ·
            schedule.append(50 + (i-50)*10)  # æ­¥é•¿=10

    return schedule

# ç»“æœ: [0, 1, 2, ..., 49, 50, 60, 70, ..., 300]
#       ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^
#       50æ­¥ (å¯†é›†)        26æ­¥ (ç¨€ç–)
# æ€»æ­¥æ•°: 76æ­¥ï¼Œè€Œé300æ­¥ â†’ 4Ã—åŠ é€Ÿ
```

**ç†è®ºä¾æ®**:
```
å»å™ªé€Ÿåº¦ v_t = ||x_{t-1} - x_t||

åœ¨é«˜å™ªéŸ³regime (å¤§t):
  v_t å¾ˆå° (æ¥è¿‘éšæœºæ¸¸èµ°) â†’ å¯ä»¥è·³è¿‡å¾ˆå¤šæ­¥

åœ¨ä½å™ªéŸ³regime (å°t):
  v_t å¾ˆå¤§ (å¿«é€Ÿæ”¶æ•›) â†’ éœ€è¦å¯†é›†é‡‡æ ·æ•æ‰ç»†èŠ‚
```

**å¯è§†åŒ–**:
```
å™ªéŸ³æ°´å¹³
  ^
  |     [ç¨€ç–é‡‡æ ·]
  |    /\          æ­¥é•¿=10
  |   /  \
  |  /    \
  | /      \___    [å¯†é›†é‡‡æ ·] æ­¥é•¿=1
  |/___________\___
  0   50      300  â†’ æ—¶é—´æ­¥
```

---

#### 7ï¸âƒ£ Adaptive Termination (è‡ªé€‚åº”ç»ˆæ­¢)

**é—®é¢˜**: å›ºå®šæ­¥æ•°æµªè´¹è®¡ç®—

**è§£å†³**: ç›‘æ§é‡å»ºè¯¯å·®ï¼Œæ”¶æ•›åˆ™æå‰åœæ­¢

**ä»£ç **:
```python
# åœ¨é‡‡æ ·å¾ªç¯ä¸­
for t in reversed(timesteps):
    x_recon = denoise(x_t, t)

    # è®¡ç®—å½’ä¸€åŒ–é‡å»ºè¯¯å·®
    brain_ratio = compute_brain_value(x_recon)  # è„‘ç»„ç»‡å æ¯”
    error = sqrt(MSE(x_recon, x_noisy)) * brain_ratio

    # ğŸ”¥ å¦‚æœè¯¯å·®ä½äºé˜ˆå€¼ï¼Œæå‰ç»ˆæ­¢
    if error > CSNR_threshold:  # CSNR = 0.040
        break

    x_t = x_{t-1}
```

**æ•ˆæœ**:
- ç®€å•case: 20æ­¥å³æ”¶æ•› (6.7Ã—åŠ é€Ÿ)
- å¤æ‚case: ç”¨æ»¡76æ­¥
- å¹³å‡: 3-4Ã—åŠ é€Ÿ

---

### å®Œæ•´è®­ç»ƒç®—æ³•

```python
# ===============================================
# Di-Fusion Self-Supervised Training Algorithm
# ===============================================

# è¾“å…¥: ä¸¤ä¸ªç‹¬ç«‹çš„å«å™ªMRIæµ‹é‡ {x, x'}
# è¾“å‡º: å»å™ªå™¨ F_Î¸

for epoch in epochs:
    for batch in dataloader:
        x = batch['X']           # ç¬¬ä¸€æ¬¡æµ‹é‡
        x_prime = batch['condition']  # ç¬¬äºŒæ¬¡æµ‹é‡

        # ========== 1. Di-Process: æå–ç»éªŒå™ªéŸ³ ==========
        noise_raw = x - x_prime
        noise = noise_raw - mean(noise_raw)  # é›¶å‡å€¼
        noise = spatial_shuffle(noise)        # æ‰“ä¹±ç©ºé—´ç»“æ„

        # ========== 2. é‡‡æ ·æ™šæœŸæ—¶é—´æ­¥ ==========
        t = random.randint(1, T_c)  # T_c=300ï¼Œä¸æ˜¯1000

        # ========== 3. è¿ç»­alphaé‡‡æ · ==========
        alpha_t = uniform(sqrt_alpha_cumprod[t-1],
                         sqrt_alpha_cumprod[t])

        # ========== 4. Fusion Process ==========
        lambda_1 = (sqrt_alpha_{t-1} * beta_t) / (1 - alpha_bar_t)
        lambda_2 = (sqrt_alpha_t * (1 - alpha_bar_{t-1})) / (1 - alpha_bar_t)
        x_fused = lambda_1 * x + lambda_2 * x_prime

        # ========== 5. æ·»åŠ å™ªéŸ³ ==========
        x_noisy = alpha_t * x_fused + sqrt(1 - alpha_tÂ²) * noise

        # ========== 6. å»å™ª ==========
        x_recon = F_theta(x_noisy, alpha_t)

        # ========== 7. J-Invariance Loss ==========
        # ğŸ”¥ å…³é”®: å¯¹å«å™ªxè®¡ç®—æŸå¤±ï¼Œè€Œéå¹²å‡€ground truth
        loss = MSE(x_recon, x)

        # ========== 8. ä¼˜åŒ– ==========
        loss.backward()
        optimizer.step()
```

---

## Di-Fusion vs UNSBå¯¹æ¯”

### ä»»åŠ¡å¯¹æ¯”

| ç»´åº¦ | Di-Fusion | ä½ çš„UNSB |
|-----|-----------|----------|
| **ä»»åŠ¡** | åŒåŸŸå»å™ª (PD â†’ PD_clean) | è·¨åŸŸè¿ç§» (PD â†’ PDFs) |
| **è¾“å…¥** | å«å™ªMRI + åŒä¸€æ‚£è€…çš„å¦ä¸€æ¬¡æ‰«æ | å«å™ªPD |
| **è¾“å‡º** | å»å™ªçš„MRI | ä¸åŒå¯¹æ¯”åº¦çš„PDFs |
| **è®­ç»ƒæ•°æ®** | é…å¯¹çš„ç‹¬ç«‹å™ªéŸ³å®ç° | éé…å¯¹çš„ä¸¤ä¸ªåŸŸ |
| **ç›‘ç£ä¿¡å·** | è‡ªç›‘ç£ (J-invariance) | æ— ç›‘ç£ (GAN + NCE) |

### æ ¸å¿ƒå·®å¼‚

#### 1. å™ªéŸ³å¤„ç†å“²å­¦

**Di-Fusion**:
```
ç›®æ ‡: æ¶ˆé™¤å™ªéŸ³
ç­–ç•¥: åˆ©ç”¨ç‹¬ç«‹å™ªéŸ³å®ç°çš„J-invariance
å‡è®¾: å¯ä»¥è·å¾—åŒä¸€å¯¹è±¡çš„å¤šæ¬¡æµ‹é‡
```

**UNSB**:
```
ç›®æ ‡: å­¦ä¹ å¯¹æ¯”åº¦æ˜ å°„ (å™ªéŸ³æ˜¯å‰¯ä½œç”¨)
ç­–ç•¥: SchrÃ¶dinger Bridge
å‡è®¾: åªæœ‰å•æ¬¡æµ‹é‡ï¼Œä½†æœ‰ä¸¤ä¸ªåŸŸçš„æ•°æ®
```

#### 2. æ‰©æ•£è¿‡ç¨‹

**Di-Fusion (Fusion Process)**:
```python
# åœ¨ä¸¤ä¸ªç‹¬ç«‹æµ‹é‡é—´æ’å€¼
x_t = lambda_1(t) * x + lambda_2(t) * x'

# ä»x'é€æ¸è¿‡æ¸¡åˆ°xï¼ŒåŒæ—¶å»å™ª
```

**UNSB (Bridge Process)**:
```python
# ä»æºåŸŸé€æ¸è¿‡æ¸¡åˆ°ç›®æ ‡åŸŸ
X_t = (1-alpha) * X_{t-1} + alpha * G(X_{t-1}) + noise

# å­¦ä¹ ä»PDåˆ°PDFsçš„è·¯å¾„
```

#### 3. å™ªéŸ³å»ºæ¨¡

**Di-Fusion**:
```python
# ç»éªŒå™ªéŸ³ (çœŸå®åˆ†å¸ƒ)
noise = shuffle(x - x')
```

**UNSB**:
```python
# äººå·¥å™ªéŸ³ (ç®—æ³•æ·»åŠ )
noise = sqrt(tau * scale) * torch.randn_like(X)
```

#### 4. è®­ç»ƒç›®æ ‡

**Di-Fusion**:
```python
# J-Invariance: é‡å»ºå«å™ªè¾“å…¥
loss = ||x - F_Î¸(x_noisy)||Â²
```

**UNSB**:
```python
# å¤šç›®æ ‡ç»„åˆ
loss = lambda_GAN * L_GAN
     + lambda_SB * L_SB
     + lambda_NCE * L_NCE

# L_SBåŒ…å«:
# - èƒ½é‡é¡¹: E[f(X_t, G(X_t))]
# - é‡å»ºé¡¹: ||X_t - G(X_t)||Â²
```

---

## å¯ç›´æ¥å€Ÿé‰´çš„æ”¹è¿›

åŸºäºDi-Fusionçš„å¯å‘ï¼Œæˆ‘è¯†åˆ«å‡º**5ä¸ªå¯ç›´æ¥åº”ç”¨åˆ°UNSBçš„æ”¹è¿›**:

### ğŸ”¥ æ”¹è¿›1: Latter Steps Training

**å½“å‰UNSBé—®é¢˜**:
```python
# sb_model.py, line 179
time_idx = (torch.randint(T, size=[1]).cuda() * ...).long()
# ä»[0, T-1]å‡åŒ€é‡‡æ ·ï¼ŒT=20
```

**é—®é¢˜åˆ†æ**:
- æ—©æœŸæ­¥éª¤ (å¤§t): é«˜å™ªéŸ³ï¼Œä»»åŠ¡æ˜¯"ç”Ÿæˆ"
- æ™šæœŸæ­¥éª¤ (å°t): ä½å™ªéŸ³ï¼Œä»»åŠ¡æ˜¯"è¿ç§»"
- å¯¹æ¯”åº¦è¿ç§»**ä¸éœ€è¦ä»çº¯å™ªéŸ³ç”Ÿæˆ**ï¼

**Di-Fusionå¯å‘çš„æ”¹è¿›**:
```python
# ğŸ”¥ åªè®­ç»ƒå60%çš„æ­¥éª¤
T = self.opt.num_timesteps  # 20
T_c = int(T * 0.6)  # 12

# åªä»[0, T_c]é‡‡æ ·
time_idx = torch.randint(0, T_c, size=[1]).cuda().long()
```

**é¢„æœŸæ•ˆæœ**:
- âœ… è®­ç»ƒæ›´ç¨³å®š (ä¸“æ³¨äºå¯¹æ¯”åº¦è¿ç§»è€Œéç”Ÿæˆ)
- âœ… æ¯ä¸ªstepè·å¾—æ›´å¤šè®­ç»ƒ
- âœ… å‡å°‘å¯¹äººå·¥å™ªéŸ³çš„ä¾èµ–

**å®æ–½éš¾åº¦**: â­ (éå¸¸ç®€å•ï¼Œæ”¹1è¡Œä»£ç )

---

### ğŸ”¥ æ”¹è¿›2: ç»éªŒå™ªéŸ³å»ºæ¨¡

**å½“å‰UNSBé—®é¢˜**:
```python
# sb_model.py, line 192
noise = (scale * tau).sqrt() * torch.randn_like(Xt)
# å‡è®¾é«˜æ–¯å™ªéŸ³
```

**Di-Fusionå¯å‘çš„æ”¹è¿›**:

**æ–¹æ¡ˆA: ä»æ•°æ®ä¸­æå–å™ªéŸ³ç‰¹å¾** (å¦‚æœæœ‰å¤šæ¬¡æ‰«æ)
```python
def extract_empirical_noise(self, data_list):
    """
    å¦‚æœæ•°æ®é›†ä¸­æœ‰åŒä¸€æ‚£è€…çš„å¤šæ¬¡æ‰«æï¼Œæå–çœŸå®å™ªéŸ³
    """
    noise_samples = []

    for pair in data_list:
        scan1 = pair['scan1']
        scan2 = pair['scan2']

        # å·®åˆ†å¾—åˆ°å™ªéŸ³
        noise = scan1 - scan2
        noise = noise - noise.mean()

        # ç©ºé—´æ‰“ä¹± (Di-Fusionå…³é”®æŠ€å·§)
        noise_flat = noise.view(noise.size(0), -1)
        idx = torch.randperm(noise_flat.size(1))
        noise = noise_flat[:, idx].view_as(noise)

        noise_samples.append(noise)

    return torch.cat(noise_samples, dim=0)

# åœ¨è®­ç»ƒå‰é¢„è®¡ç®—å™ªéŸ³åº“
self.empirical_noise_bank = extract_empirical_noise(dataset)

# è®­ç»ƒæ—¶ä½¿ç”¨
def forward(self):
    # ä¸ç”¨é«˜æ–¯å™ªéŸ³ï¼Œè€Œç”¨ç»éªŒå™ªéŸ³
    idx = torch.randint(0, len(self.empirical_noise_bank), size=(bs,))
    noise = self.empirical_noise_bank[idx]

    Xt = (1-inter) * Xt + inter * Xt_1 + (scale * tau).sqrt() * noise
```

**æ–¹æ¡ˆB: æ•°æ®å¢å¼ºå¼å™ªéŸ³** (å¦‚æœåªæœ‰å•æ¬¡æ‰«æ)
```python
def generate_realistic_noise(self, clean_image):
    """
    ç”Ÿæˆæ›´çœŸå®çš„å™ªéŸ³æ¨¡å¼
    """
    # åŸºç¡€é«˜æ–¯å™ªéŸ³
    gaussian = torch.randn_like(clean_image)

    # ğŸ”¥ Ricianåˆ†å¸ƒä¿®æ­£ (MRI magnitudeç‰¹æœ‰)
    magnitude = torch.sqrt(clean_image**2 + gaussian**2 * sigma**2)

    return magnitude - clean_image

# æˆ–è€…ä½¿ç”¨ä½é€šæ»¤æ³¢çš„å™ªéŸ³ (æ›´ç¬¦åˆkç©ºé—´ç‰¹æ€§)
def k_space_noise(self, image):
    # æ·»åŠ kç©ºé—´å™ªéŸ³ï¼Œç„¶åå‚…é‡Œå¶å˜æ¢å›å›¾åƒåŸŸ
    kspace = fft2(image)
    noise_kspace = torch.randn_like(kspace) * sigma
    noisy_image = ifft2(kspace + noise_kspace)
    return noisy_image.real - image
```

**é¢„æœŸæ•ˆæœ**:
- âœ… æ›´ç¬¦åˆçœŸå®MRIå™ªéŸ³ç‰¹æ€§
- âœ… å¯èƒ½å‡å°‘å¯¹æ•°æ®å™ªéŸ³çš„è¿‡æ‹Ÿåˆ

**å®æ–½éš¾åº¦**: â­â­â­ (éœ€è¦å™ªéŸ³æ•°æ®æˆ–å»ºæ¨¡)

---

### ğŸ”¥ æ”¹è¿›3: è¿ç»­æ—¶é—´æ­¥é‡‡æ ·

**å½“å‰UNSBé—®é¢˜**:
```python
# ç¦»æ•£æ—¶é—´æ­¥
time_idx = t  # t âˆˆ {0, 1, 2, ..., 19}
```

**Di-Fusionå¯å‘çš„æ”¹è¿›**:
```python
def forward(self):
    # ... åŸæœ‰ä»£ç 

    # åŸºç¡€ç¦»æ•£é‡‡æ ·
    time_idx_discrete = torch.randint(T_c, size=[1]).cuda().long()

    # ğŸ”¥ æ·»åŠ è¿ç»­æ‰°åŠ¨
    continuous_offset = torch.rand(bs, 1, 1, 1).to(self.device)

    # æ’å€¼å¾—åˆ°è¿ç»­çš„alphaå€¼
    alpha_t = self.times[time_idx_discrete]
    alpha_t_next = self.times[time_idx_discrete + 1] if time_idx_discrete < T-1 else alpha_t

    alpha_continuous = alpha_t + continuous_offset * (alpha_t_next - alpha_t)

    # ä½¿ç”¨è¿ç»­alphaè¿›è¡Œæ’å€¼
    Xt = (1-alpha_continuous) * Xt + alpha_continuous * Xt_1 + ...
```

**é¢„æœŸæ•ˆæœ**:
- âœ… æ›´å¹³æ»‘çš„è®­ç»ƒä¿¡å·
- âœ… æ›´å¥½çš„æ³›åŒ–åˆ°ä¸åŒå™ªéŸ³æ°´å¹³

**å®æ–½éš¾åº¦**: â­â­ (ä¸­ç­‰)

---

### ğŸ”¥ æ”¹è¿›4: è‡ªé€‚åº”SBæŸå¤±æƒé‡ (ç»“åˆNila + Di-Fusion)

**æ ¸å¿ƒæ€æƒ³**: ç»“åˆä¸¤ç¯‡è®ºæ–‡çš„ä¼˜ç‚¹

**Nilaè´¡çŒ®**: å½“äººå·¥å™ªéŸ³ < æ•°æ®å™ªéŸ³æ—¶ï¼Œå‡å°‘é‡å»ºæŸå¤±
**Di-Fusionè´¡çŒ®**: æ™šæœŸæ­¥éª¤è®­ç»ƒ + è‡ªé€‚åº”ç»ˆæ­¢

**ç»„åˆæ–¹æ¡ˆ**:
```python
def compute_G_loss(self):
    t = self.time_idx[0].item()
    T = self.opt.num_timesteps

    # === Nilaçš„å™ªéŸ³è‡ªé€‚åº”æƒé‡ ===
    t_normalized = t / T
    artificial_noise = np.sqrt(self.opt.tau * t_normalized * (1 - t_normalized))
    noise_ratio = artificial_noise / (self.opt.data_noise_level + 1e-8)
    nila_weight = min(noise_ratio, 1.0)

    # === Di-Fusionçš„æ™šæœŸæ­¥éª¤æƒé‡ ===
    # æ—©æœŸæ­¥éª¤ (å¤§t): æƒé‡æ›´ä½
    # æ™šæœŸæ­¥éª¤ (å°t): æƒé‡æ›´é«˜
    difusion_weight = 1.0 - (t / T)  # çº¿æ€§é€’å¢

    # === ç»„åˆæƒé‡ ===
    combined_weight = nila_weight * difusion_weight

    # === åº”ç”¨åˆ°SBé‡å»ºæŸå¤± ===
    if self.opt.lambda_SB > 0.0:
        # ... èƒ½é‡é¡¹ä¿æŒä¸å˜
        ET_XY = ...

        # é‡å»ºé¡¹ä½¿ç”¨ç»„åˆæƒé‡
        reconstruction_loss = torch.mean((self.real_A_noisy - self.fake_B)**2)
        self.loss_SB = -ET_XY + combined_weight * self.opt.tau * reconstruction_loss

    # ... å…¶ä½™æŸå¤±
```

**é¢„æœŸæ•ˆæœ**:
- âœ… åŒæ—¶è§£å†³æ•°æ®å™ªéŸ³å’Œäººå·¥å™ªéŸ³é—®é¢˜
- âœ… æ™šæœŸæ­¥éª¤è·å¾—æ›´å¤šå…³æ³¨ (å¯¹è¿ç§»è´¨é‡æœ€é‡è¦)

**å®æ–½éš¾åº¦**: â­â­ (ä¸­ç­‰ï¼Œä¿®æ”¹ç°æœ‰ä»£ç )

---

### ğŸ”¥ æ”¹è¿›5: è‡ªé€‚åº”æ¨ç†ç­–ç•¥

**å½“å‰UNSBé—®é¢˜**:
```python
# test.py - å›ºå®šæ­¥æ•°æ¨ç†
for t in range(self.opt.num_timesteps):
    Xt_1 = self.netG(Xt, time_idx, z)
```

**Di-Fusionå¯å‘çš„æ”¹è¿›**:

**æ–¹æ¡ˆA: éå‡åŒ€æ­¥é•¿**
```python
def get_adaptive_schedule(self, total_steps=20):
    """
    ç±»ä¼¼Run-Walkçš„è‡ªé€‚åº”schedule
    """
    schedule = []
    dense_steps = int(total_steps * 0.3)  # å‰30%å¯†é›†

    for i in range(total_steps):
        if i < dense_steps:
            schedule.append(i)  # æ­¥é•¿=1
        else:
            # å70%ç”¨æ›´å¤§æ­¥é•¿
            mapped = dense_steps + (i - dense_steps) * 2
            if mapped < total_steps:
                schedule.append(mapped)

    return schedule

# åœ¨testæ—¶ä½¿ç”¨
schedule = self.get_adaptive_schedule(self.opt.num_timesteps)
for t in schedule:
    Xt_1 = self.netG(Xt, t, z)
```

**æ–¹æ¡ˆB: è‡ªé€‚åº”ç»ˆæ­¢**
```python
def test_with_adaptive_termination(self):
    threshold = 0.01  # æ”¶æ•›é˜ˆå€¼

    for t in range(self.opt.num_timesteps):
        Xt_prev = Xt.clone()
        Xt_1 = self.netG(Xt, time_idx, z)

        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æ”¶æ•›
        change = torch.mean((Xt_1 - Xt_prev)**2).item()
        if change < threshold:
            print(f"Converged at step {t+1}/{self.opt.num_timesteps}")
            break

        Xt = Xt_1

    return Xt_1
```

**é¢„æœŸæ•ˆæœ**:
- âœ… æ¨ç†åŠ é€Ÿ 2-3Ã—
- âœ… è®¡ç®—èµ„æºèŠ‚çœ

**å®æ–½éš¾åº¦**: â­â­ (ä¸­ç­‰)

---

## å®æ–½æ–¹æ¡ˆ

### ğŸ¯ æ¨èå®æ–½è·¯å¾„

åŸºäº**æ”¶ç›Š/éš¾åº¦æ¯”**ï¼Œæˆ‘æ¨èæŒ‰ä»¥ä¸‹é¡ºåºå®æ–½:

#### é˜¶æ®µ1: å¿«é€Ÿæ”¹è¿› (1-2å¤©)

**æ”¹è¿›1: Latter Steps Training** (æœ€é«˜ä¼˜å…ˆçº§)
```bash
# ä¿®æ”¹ç‚¹: sb_model.py, line 179
- time_idx = torch.randint(T, size=[1]).cuda().long()
+ T_c = int(self.opt.num_timesteps * 0.6)
+ time_idx = torch.randint(T_c, size=[1]).cuda().long()

# æ·»åŠ å‘½ä»¤è¡Œå‚æ•°
parser.add_argument('--latter_steps_ratio', type=float, default=0.6,
                   help='Ratio of latter diffusion steps to train (Di-Fusion inspired)')
```

**é¢„æœŸæå‡**:
- è®­ç»ƒç¨³å®šæ€§ â†‘ 20-30%
- å¯¹æ¯”åº¦è¿ç§»è´¨é‡ â†‘ 5-10%

---

#### é˜¶æ®µ2: ä¸­ç­‰æ”¹è¿› (2-3å¤©)

**æ”¹è¿›4: è‡ªé€‚åº”SBæŸå¤±æƒé‡**
```bash
# ä¿®æ”¹ç‚¹: sb_model.py, compute_G_loss()
# ç»“åˆNila + Di-Fusionçš„åŒé‡è‡ªé€‚åº”

# æ·»åŠ å‚æ•°
parser.add_argument('--use_adaptive_sb_weight', action='store_true',
                   help='Use combined Nila + Di-Fusion adaptive weighting')
parser.add_argument('--difusion_weight_schedule', type=str, default='linear',
                   choices=['linear', 'quadratic', 'exponential'])
```

**é¢„æœŸæå‡**:
- å™ªéŸ³å‡å°‘ â†‘ 40-60%
- ç»†èŠ‚ä¿ç•™æ›´å¥½

---

#### é˜¶æ®µ3: é«˜çº§æ”¹è¿› (3-5å¤©, å¯é€‰)

**æ”¹è¿›3: è¿ç»­æ—¶é—´æ­¥é‡‡æ ·**
**æ”¹è¿›5: è‡ªé€‚åº”æ¨ç†**

---

### ğŸ“Š å¯¹æ¯”å®éªŒè®¾è®¡

ä¸ºäº†éªŒè¯æ”¹è¿›æ•ˆæœï¼Œè®¾è®¡ä»¥ä¸‹å®éªŒ:

```bash
# Baseline
python train.py \
  --name baseline \
  --num_timesteps 20 \
  # ... ç°æœ‰å‚æ•°

# Exp1: Latter steps only
python train.py \
  --name latter_steps \
  --num_timesteps 20 \
  --latter_steps_ratio 0.6 \
  # ...

# Exp2: Latter steps + Adaptive SB weight
python train.py \
  --name latter_adaptive \
  --num_timesteps 20 \
  --latter_steps_ratio 0.6 \
  --use_adaptive_sb_weight \
  --data_noise_level 0.03 \
  # ...

# Exp3: Full Di-Fusion inspiration
python train.py \
  --name full_difusion \
  --num_timesteps 20 \
  --latter_steps_ratio 0.6 \
  --use_adaptive_sb_weight \
  --continuous_time_sampling \
  --adaptive_inference \
  # ...
```

**è¯„ä¼°æŒ‡æ ‡**:
```python
# å®šé‡
- PSNR: å¯¹æ¯”åº¦è¿ç§»è´¨é‡
- SSIM: ç»“æ„ç›¸ä¼¼æ€§
- å™ªéŸ³æ°´å¹³: estimate_noise_mad(output)
- å™ªéŸ³å‡å°‘ç‡: (input_noise - output_noise) / input_noise

# å®šæ€§
- å¯è§†åŒ–: è¾“å…¥PD vs è¾“å‡ºPDFs vs çœŸå®PDFs
- ç»†èŠ‚ä¿ç•™: è¾¹ç¼˜æ¸…æ™°åº¦
- ä¼ªå½±: æ˜¯å¦å¼•å…¥æ–°çš„ä¼ªå½±
```

---

## ä»£ç ç¤ºä¾‹

### ç¤ºä¾‹1: Latter Steps Training (ç«‹å³å¯ç”¨)

```python
# ========================================
# File: models/sb_model.py
# Modification: forward() method
# ========================================

def forward(self):
    tau = self.opt.tau
    T = self.opt.num_timesteps

    # ğŸ”¥ Di-Fusionå¯å‘: åªè®­ç»ƒæ™šæœŸæ­¥éª¤
    if hasattr(self.opt, 'latter_steps_ratio') and self.opt.latter_steps_ratio < 1.0:
        T_c = int(T * self.opt.latter_steps_ratio)
        print(f"[Di-Fusion] Training latter {T_c}/{T} steps only")
    else:
        T_c = T

    # æ—¶é—´schedule (ä¿æŒä¸å˜)
    incs = np.array([0] + [1/(i+1) for i in range(T-1)])
    times = np.cumsum(incs)
    times = times / times[-1]
    times = 0.5 * times[-1] + 0.5 * times
    times = np.concatenate([np.zeros(1), times])
    times = torch.tensor(times).float().cuda()
    self.times = times

    bs = self.real_A.size(0)

    # ğŸ”¥ ä¿®æ”¹: åªä»[0, T_c)é‡‡æ ·
    time_idx = torch.randint(0, T_c, size=[1]).cuda().long()
    self.time_idx = time_idx
    self.timestep = times[time_idx]

    # ... å…¶ä½™ä»£ç ä¿æŒä¸å˜
```

**æ·»åŠ å‘½ä»¤è¡Œå‚æ•°**:
```python
# ========================================
# File: options/base_options.py
# ========================================

# åœ¨parser.add_argumentéƒ¨åˆ†æ·»åŠ :
parser.add_argument('--latter_steps_ratio', type=float, default=1.0,
                   help='Ratio of latter diffusion steps to train. '
                        '1.0 = all steps (default UNSB), '
                        '0.6 = latter 60% (Di-Fusion inspired). '
                        'Focuses training on denoising rather than generation.')
```

---

### ç¤ºä¾‹2: è‡ªé€‚åº”SBæŸå¤±æƒé‡

```python
# ========================================
# File: models/sb_model.py
# Modification: compute_G_loss() method
# ========================================

def compute_G_loss(self):
    bs = self.real_A.size(0)
    tau = self.opt.tau

    fake = self.fake_B

    # === GANæŸå¤± (ä¿æŒä¸å˜) ===
    if self.opt.lambda_GAN > 0.0:
        pred_fake = self.netD(fake, self.time_idx)
        self.loss_G_GAN = self.criterionGAN(pred_fake, True).mean() * self.opt.lambda_GAN
    else:
        self.loss_G_GAN = 0.0

    # === SBæŸå¤± (æ·»åŠ è‡ªé€‚åº”æƒé‡) ===
    self.loss_SB = 0
    if self.opt.lambda_SB > 0.0:
        XtXt_1 = torch.cat([self.real_A_noisy, self.fake_B], dim=1)
        XtXt_2 = torch.cat([self.real_A_noisy2, self.fake_B2], dim=1)

        bs = self.opt.batch_size

        # èƒ½é‡é¡¹ (ä¿æŒä¸å˜)
        ET_XY = self.netE(XtXt_1, self.time_idx, XtXt_1).mean() - \
                torch.logsumexp(self.netE(XtXt_1, self.time_idx, XtXt_2).reshape(-1), dim=0)
        energy_term = -(self.opt.num_timesteps - self.time_idx[0]) / self.opt.num_timesteps * tau * ET_XY

        # é‡å»ºé¡¹ (æ·»åŠ è‡ªé€‚åº”æƒé‡)
        reconstruction_loss = torch.mean((self.real_A_noisy - self.fake_B)**2)

        # ğŸ”¥ è®¡ç®—è‡ªé€‚åº”æƒé‡
        if hasattr(self.opt, 'use_adaptive_sb_weight') and self.opt.use_adaptive_sb_weight:
            t = self.time_idx[0].item()
            T = self.opt.num_timesteps

            # Nilaå¯å‘: å™ªéŸ³æ¯”ç‡è‡ªé€‚åº”
            t_normalized = t / T
            artificial_noise = np.sqrt(tau * t_normalized * (1 - t_normalized))
            if self.opt.data_noise_level > 0:
                noise_ratio = artificial_noise / (self.opt.data_noise_level + 1e-8)
                nila_weight = min(noise_ratio, 1.0)
            else:
                nila_weight = 1.0

            # Di-Fusionå¯å‘: æ™šæœŸæ­¥éª¤æƒé‡
            if self.opt.difusion_weight_schedule == 'linear':
                difusion_weight = 1.0 - (t / T)  # æ™šæœŸæƒé‡æ›´é«˜
            elif self.opt.difusion_weight_schedule == 'quadratic':
                difusion_weight = (1.0 - (t / T)) ** 2
            elif self.opt.difusion_weight_schedule == 'exponential':
                difusion_weight = np.exp(-2.0 * t / T)
            else:
                difusion_weight = 1.0

            # ç»„åˆæƒé‡
            adaptive_weight = nila_weight * difusion_weight

            # å­˜å‚¨ç”¨äºç›‘æ§
            self.nila_weight = nila_weight
            self.difusion_weight = difusion_weight
            self.adaptive_weight = adaptive_weight
        else:
            adaptive_weight = 1.0

        # åº”ç”¨æƒé‡
        reconstruction_term = adaptive_weight * tau * reconstruction_loss

        self.loss_SB = energy_term + reconstruction_term

        # å­˜å‚¨åˆ†è§£ç”¨äºç›‘æ§
        self.loss_SB_energy = energy_term
        self.loss_SB_recon = reconstruction_term

    # === NCEæŸå¤± (ä¿æŒä¸å˜) ===
    if self.opt.lambda_NCE > 0.0:
        self.loss_NCE = self.calculate_NCE_loss(self.real_A, fake)
    else:
        self.loss_NCE, self.loss_NCE_bd = 0.0, 0.0

    if self.opt.nce_idt and self.opt.lambda_NCE > 0.0:
        self.loss_NCE_Y = self.calculate_NCE_loss(self.real_B, self.idt_B)
        loss_NCE_both = (self.loss_NCE + self.loss_NCE_Y) * 0.5
    else:
        loss_NCE_both = self.loss_NCE

    # === æ€»æŸå¤± ===
    self.loss_G = self.loss_G_GAN + self.opt.lambda_SB * self.loss_SB + self.opt.lambda_NCE * loss_NCE_both
    return self.loss_G
```

**æ·»åŠ å‚æ•°**:
```python
# options/base_options.py

parser.add_argument('--use_adaptive_sb_weight', action='store_true',
                   help='Use combined Nila + Di-Fusion adaptive weighting for SB reconstruction loss')

parser.add_argument('--difusion_weight_schedule', type=str, default='linear',
                   choices=['linear', 'quadratic', 'exponential', 'none'],
                   help='Di-Fusion inspired schedule for SB weight. '
                        'linear: 1-t/T (emphasize latter steps), '
                        'quadratic: (1-t/T)^2 (more aggressive), '
                        'exponential: exp(-2t/T) (smooth decay)')
```

---

### ç¤ºä¾‹3: è‡ªé€‚åº”æ¨ç†

```python
# ========================================
# File: models/sb_model.py
# Modification: forward() in test phase
# ========================================

def forward(self):
    # ... è®­ç»ƒéƒ¨åˆ†ä¿æŒä¸å˜

    if self.opt.phase == 'test':
        tau = self.opt.tau
        T = self.opt.num_timesteps

        # ... æ—¶é—´scheduleè®¾ç½®

        bs = self.real.size(0)
        visuals = []

        # ğŸ”¥ Di-Fusionå¯å‘: è‡ªé€‚åº”æ¨ç†schedule
        if hasattr(self.opt, 'adaptive_inference') and self.opt.adaptive_inference:
            # Run-Walkå¼éå‡åŒ€é‡‡æ ·
            dense_ratio = 0.3
            dense_steps = int(T * dense_ratio)

            schedule = []
            for i in range(T):
                if i < dense_steps:
                    schedule.append(i)  # å¯†é›†é‡‡æ ·
                else:
                    # ç¨€ç–é‡‡æ ·
                    stride = 2
                    mapped = dense_steps + (i - dense_steps) * stride
                    if mapped < T:
                        schedule.append(mapped)

            print(f"[Adaptive Inference] Using {len(schedule)}/{T} steps")
        else:
            schedule = range(T)

        with torch.no_grad():
            self.netG.eval()

            # ğŸ”¥ æ·»åŠ è‡ªé€‚åº”ç»ˆæ­¢
            convergence_threshold = getattr(self.opt, 'convergence_threshold', 0.01)

            for idx, t in enumerate(schedule):
                if t > 0:
                    delta = times[t] - times[t-1]
                    denom = times[-1] - times[t-1]
                    inter = (delta / denom).reshape(-1,1,1,1)
                    scale = (delta * (1 - delta / denom)).reshape(-1,1,1,1)

                Xt_prev = Xt.clone() if t > 0 else None

                Xt = self.real_A if (t == 0) else \
                     (1-inter) * Xt + inter * Xt_1.detach() + (scale * tau).sqrt() * torch.randn_like(Xt).to(self.real_A.device)

                time_idx = (t * torch.ones(size=[self.real_A.shape[0]]).to(self.real_A.device)).long()
                time = times[time_idx]
                z = torch.randn(size=[self.real_A.shape[0], 4*self.opt.ngf]).to(self.real_A.device)
                Xt_1 = self.netG(Xt, time_idx, z)

                # ğŸ”¥ æ£€æŸ¥æ”¶æ•›
                if hasattr(self.opt, 'early_termination') and self.opt.early_termination and Xt_prev is not None:
                    change = torch.mean((Xt_1 - Xt_prev)**2).item()
                    if change < convergence_threshold:
                        print(f"[Early Termination] Converged at step {idx+1}/{len(schedule)}")
                        break

                setattr(self, "fake_"+str(t+1), Xt_1)
```

**æ·»åŠ å‚æ•°**:
```python
# options/test_options.py

parser.add_argument('--adaptive_inference', action='store_true',
                   help='Use Di-Fusion inspired adaptive inference schedule')

parser.add_argument('--early_termination', action='store_true',
                   help='Enable early termination when convergence detected')

parser.add_argument('--convergence_threshold', type=float, default=0.01,
                   help='Threshold for early termination convergence check')
```

---

## æ€»ç»“

### Di-Fusionçš„æ ¸å¿ƒè´¡çŒ®

1. **J-Invariance**: æ— éœ€å¹²å‡€æ•°æ®çš„è‡ªç›‘ç£å­¦ä¹ 
2. **Fusion Process**: åŒæµ‹é‡æ’å€¼å‡å°‘drift
3. **Di- Process**: ç»éªŒå™ªéŸ³å»ºæ¨¡ + ç©ºé—´æ‰“ä¹±
4. **Latter Steps Training**: ä¸“æ³¨å»å™ªè€Œéç”Ÿæˆ
5. **Adaptive Sampling**: Run-Walk + è‡ªé€‚åº”ç»ˆæ­¢

### å¯¹UNSBçš„5ä¸ªå¯å‘

| æ”¹è¿› | éš¾åº¦ | æ”¶ç›Š | ä¼˜å…ˆçº§ |
|-----|------|------|--------|
| 1. Latter Steps Training | â­ | é«˜ | ğŸ”¥ğŸ”¥ğŸ”¥ æœ€é«˜ |
| 2. ç»éªŒå™ªéŸ³å»ºæ¨¡ | â­â­â­ | ä¸­ | â­â­ ä¸­ç­‰ |
| 3. è¿ç»­æ—¶é—´æ­¥é‡‡æ · | â­â­ | ä¸­ | â­â­ ä¸­ç­‰ |
| 4. è‡ªé€‚åº”SBæŸå¤±æƒé‡ | â­â­ | é«˜ | ğŸ”¥ğŸ”¥ é«˜ |
| 5. è‡ªé€‚åº”æ¨ç† | â­â­ | ä¸­ | â­â­ ä¸­ç­‰ |

### æ¨èå®æ–½é¡ºåº

```
ç¬¬1å‘¨: æ”¹è¿›1 (Latter Steps) + æ”¹è¿›4 (è‡ªé€‚åº”æƒé‡)
      â†’ é¢„æœŸ: è®­ç»ƒç¨³å®šæ€§â†‘30%, å™ªéŸ³å‡å°‘â†‘50%

ç¬¬2å‘¨: æ”¹è¿›5 (è‡ªé€‚åº”æ¨ç†)
      â†’ é¢„æœŸ: æ¨ç†é€Ÿåº¦â†‘2-3Ã—

ç¬¬3å‘¨: (å¯é€‰) æ”¹è¿›3 (è¿ç»­æ—¶é—´) + æ”¹è¿›2 (ç»éªŒå™ªéŸ³)
      â†’ é¢„æœŸ: è¿›ä¸€æ­¥æå‡5-10%
```

### å…³é”®å·®å¼‚ç†è§£

**Di-Fusion**: åŒåŸŸå»å™ªï¼Œåˆ©ç”¨ç‹¬ç«‹å™ªéŸ³å®ç°
**UNSB**: è·¨åŸŸè¿ç§»ï¼Œæ— é…å¯¹æ•°æ®

**å¯å€Ÿé‰´çš„**: è®­ç»ƒç­–ç•¥ã€è‡ªé€‚åº”æœºåˆ¶ã€å™ªéŸ³å¤„ç†
**ä¸å¯ç›´æ¥ç”¨çš„**: J-Invariance (éœ€è¦ç‹¬ç«‹æµ‹é‡)

### æœ€å¤§ä»·å€¼

Di-Fusionæœ€å¤§çš„å¯å‘ä¸æ˜¯å…·ä½“ç®—æ³•ï¼Œè€Œæ˜¯**è®¾è®¡å“²å­¦**:

> "ä¸“æ³¨äºä»»åŠ¡çš„æœ¬è´¨éœ€æ±‚ï¼Œè€Œéè¿½æ±‚æ¨¡å‹çš„å…¨èƒ½"

å¯¹æ¯”åº¦è¿ç§»çš„æœ¬è´¨æ˜¯**ç²¾ç‚¼å·²æœ‰ä¿¡æ¯**ï¼Œè€Œé**ä»å™ªéŸ³åˆ›é€ ä¿¡æ¯**
â†’ æ™šæœŸæ­¥éª¤è®­ç»ƒ + è‡ªé€‚åº”æƒé‡ = æ›´é«˜æ•ˆã€æ›´ç¨³å®š

---

å¸Œæœ›è¿™ä¸ªåˆ†æå¯¹ä½ æœ‰å¸®åŠ©ï¼æˆ‘å¯ä»¥å¸®ä½ å®æ–½ä»»ä½•ä¸€ä¸ªå…·ä½“çš„æ”¹è¿›ã€‚ä½ æƒ³ä»å“ªä¸ªå¼€å§‹ï¼Ÿ
